{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NLP-BASED INTERVIEW SYSTEM**\n",
    "#### This project develops a chatbot-like system that conducts data science interviews, evaluates responses, and provides feedback using NLP models.\n",
    "#### ***Data Requirements***\n",
    "##### - A dataset of high-quality interview questions and answers asked on data science interviews.\n",
    "##### - Pre-trained NLP models for sentense embedding and evaluation.\n",
    "##### - User responses for evaluation.\n",
    "#### ***Goals***\n",
    "##### - Implement an interview system that simulates a real world interview.\n",
    "##### - Compare different models.\n",
    "##### - Develop a scoring mechanism on how a user answered the asked interview question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading my libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "import string\n",
    "import gensim.downloader as api\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Collection using web scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>Explain the difference between L1 and L2 regul...</td>\n",
       "      <td>In my graduate research project at Stanford, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>How would you detect and handle outliers in a ...</td>\n",
       "      <td>During my internship at Tesla, I worked with s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>Design a simple recommendation system for an o...</td>\n",
       "      <td>I'd start with a collaborative filtering appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Behavioral</td>\n",
       "      <td>Soft Skills</td>\n",
       "      <td>Tell me about a time when you had to learn a n...</td>\n",
       "      <td>During my internship at Facebook, I needed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>How would you design and evaluate a multi-arme...</td>\n",
       "      <td>At Booking.com, I implemented an epsilon-greed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type     Category                                           Question  \\\n",
       "0   Technical           ML  Explain the difference between L1 and L2 regul...   \n",
       "1   Technical           ML  How would you detect and handle outliers in a ...   \n",
       "2   Technical           ML  Design a simple recommendation system for an o...   \n",
       "3  Behavioral  Soft Skills  Tell me about a time when you had to learn a n...   \n",
       "4   Technical           ML  How would you design and evaluate a multi-arme...   \n",
       "\n",
       "                                              Answer  \n",
       "0  In my graduate research project at Stanford, I...  \n",
       "1  During my internship at Tesla, I worked with s...  \n",
       "2  I'd start with a collaborative filtering appro...  \n",
       "3  During my internship at Facebook, I needed to ...  \n",
       "4  At Booking.com, I implemented an epsilon-greed...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load local HTML\n",
    "with open(\"C:/Users/Admin/Desktop/Data Scientist Interview Questions and Answers (All Levels) _ Himalayas.html\", encoding='utf-8') as file:\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "# Extract <p> and <ol> together (we’ll check for sequences)\n",
    "elements = soup.find_all(['p', 'ol'])\n",
    "\n",
    "qa_pairs = []\n",
    "i = 0\n",
    "while i < len(elements):\n",
    "    el = elements[i]\n",
    "\n",
    "    # Check for question\n",
    "    if el.name == 'p' and el.find('strong') and \"sample answer\" not in el.text.lower():\n",
    "        question = el.get_text(strip=True)\n",
    "\n",
    "        # Look ahead for answer\n",
    "        answer = \"\"\n",
    "        if i + 1 < len(elements):\n",
    "            next_el = elements[i + 1]\n",
    "            \n",
    "            # Case: <p> with <em> inside\n",
    "            if next_el.name == 'p' and next_el.find('em'):\n",
    "                answer += next_el.find('em').get_text(strip=True)\n",
    "\n",
    "                # Check if another <ol> follows\n",
    "                if i + 2 < len(elements) and elements[i + 2].name == 'ol':\n",
    "                    bullets = elements[i + 2].find_all('li')\n",
    "                    answer += \"\\n\" + \"\\n\".join([f\"- {li.get_text(strip=True)}\" for li in bullets])\n",
    "                    i += 3\n",
    "                else:\n",
    "                    i += 2\n",
    "            else:\n",
    "                i += 1  # move forward normally if no answer found\n",
    "        else:\n",
    "            i += 1\n",
    "        \n",
    "        if question and answer:\n",
    "            qa_pairs.append({'Question': question, 'Answer': answer})\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Remove leading/trailing whitespace\n",
    "df['Question'] = df['Question'].astype(str).str.strip()\n",
    "df['Answer'] = df['Answer'].astype(str).str.strip()\n",
    "\n",
    "# Remove any leftover HTML tags (if scraping missed any)\n",
    "df['Question'] = df['Question'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "df['Answer'] = df['Answer'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "\n",
    "\n",
    "#  Normalize (remove excessive newlines, lowercasing)\n",
    "df['Answer'] = df['Answer'].str.replace(r'\\n+', '\\n', regex=True)\n",
    "df['Question'] = df['Question'].str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Remove starting and ending quotation marks\n",
    "df['Answer'] = df['Answer'].str.strip('\"“”')\n",
    "\n",
    "# 'df' has a 'Question' column\n",
    "pattern = r\"^(Tell me about a|Describe a situation|Describe how ).*\"\n",
    "\n",
    "# Find rows where 'Question' starts with the given patterns\n",
    "matching_rows = df[df['Question'].str.match(pattern)]\n",
    "\n",
    "# Update the original DataFrame with 'Behavioral' as Type and 'Soft Skills' as Category\n",
    "df.loc[df['Question'].str.match(pattern), 'Type'] = 'Behavioral'\n",
    "df.loc[df['Question'].str.match(pattern), 'Category'] = 'Soft Skills'\n",
    "\n",
    "df['Type'] = df['Type'].fillna('Technical')\n",
    "df['Category'] = df['Category'].fillna('ML')\n",
    "\n",
    "df = df[['Type', 'Category', 'Question', 'Answer']]\n",
    "#LOADING THE DATAFRAME\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What are autoencoders? Explain the different l...</td>\n",
       "      <td>Autoencoders are one of the deep learning type...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>What is an activation function and discuss the...</td>\n",
       "      <td>In mathematical terms, the activation function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>You are using a deep neural network for a pred...</td>\n",
       "      <td>Hyperparameters are any parameter in the model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Can you explain the parameter sharing concept ...</td>\n",
       "      <td>Parameter sharing is the method of sharing wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Describe the architecture of a typical Convolu...</td>\n",
       "      <td>In a typical CNN architecture, a few convoluti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type       Category  \\\n",
       "0  Technical  Deep Learning   \n",
       "1  Technical  Deep Learning   \n",
       "2  Technical  Deep Learning   \n",
       "3  Technical  Deep Learning   \n",
       "4  Technical  Deep Learning   \n",
       "\n",
       "                                            Question  \\\n",
       "0  What are autoencoders? Explain the different l...   \n",
       "1  What is an activation function and discuss the...   \n",
       "2  You are using a deep neural network for a pred...   \n",
       "3  Can you explain the parameter sharing concept ...   \n",
       "4  Describe the architecture of a typical Convolu...   \n",
       "\n",
       "                                              Answer  \n",
       "0  Autoencoders are one of the deep learning type...  \n",
       "1  In mathematical terms, the activation function...  \n",
       "2  Hyperparameters are any parameter in the model...  \n",
       "3  Parameter sharing is the method of sharing wei...  \n",
       "4  In a typical CNN architecture, a few convoluti...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the response\n",
    "url = 'https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Deep%20Learning%20Questions%20%26%20Answers%20for%20Data%20Scientists.md'\n",
    "response = requests.get(url)\n",
    "\n",
    "#print the text of the response\n",
    "md_text = response.text\n",
    "md_text\n",
    "\n",
    "#where the text is located\n",
    "pattern = r'###\\s*Q\\d+:\\s*(.*?)\\s*###\\s*\\n+Answer:\\s*(.*?)(?=\\n### Q\\d+:|$)'\n",
    "qa_matches = re.findall(pattern, md_text, re.DOTALL)\n",
    "\n",
    "# Step 3: Clean and save\n",
    "qa_list = [{'Question': q.strip(), 'Answer': a.strip()} for q, a in qa_matches]\n",
    "df1 = pd.DataFrame(qa_list)\n",
    "\n",
    "# Remove leading/trailing whitespace\n",
    "df1['Question'] = df1['Question'].astype(str).str.strip()\n",
    "df1['Answer'] = df1['Answer'].astype(str).str.strip()\n",
    "\n",
    "# Remove any leftover HTML tags (if scraping missed any)\n",
    "df1['Question'] = df1['Question'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "df1['Answer'] = df1['Answer'].apply(lambda x: re.sub(r'<.*?>', '', x))\n",
    "\n",
    "# Normalize (remove excessive newlines, lowercasing)\n",
    "df1['Answer'] = df1['Answer'].str.replace(r'\\n+', '\\n', regex=True)\n",
    "df1['Question'] = df1['Question'].str.replace(r'\\n+', ' ', regex=True)\n",
    "\n",
    "# Function to clean markdown links, images, and plain URLs\n",
    "def remove_links(text):\n",
    "    # Remove image markdown: ![alt](url)\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove markdown links: [text](url)\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove standalone URLs: http:// or https://\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # Clean up leftover blank lines\n",
    "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Apply it to both question and answer columns\n",
    "#df['question'] = df['question'].apply(remove_links)\n",
    "df1['Answer'] = df1['Answer'].apply(remove_links)\n",
    "\n",
    "#add in the colmn names\n",
    "df1['Type'] = 'Technical'       # Empty column for topic\n",
    "df1['Category'] = 'Deep Learning' # Empty column for category\n",
    "df1 = df1[['Type', 'Category', 'Question', 'Answer']]\n",
    "\n",
    "#load the dataframe\n",
    "df1.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>Explain the difference between L1 and L2 regul...</td>\n",
       "      <td>In my graduate research project at Stanford, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>How would you detect and handle outliers in a ...</td>\n",
       "      <td>During my internship at Tesla, I worked with s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>Design a simple recommendation system for an o...</td>\n",
       "      <td>I'd start with a collaborative filtering appro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Behavioral</td>\n",
       "      <td>Soft Skills</td>\n",
       "      <td>Tell me about a time when you had to learn a n...</td>\n",
       "      <td>During my internship at Facebook, I needed to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical</td>\n",
       "      <td>ML</td>\n",
       "      <td>How would you design and evaluate a multi-arme...</td>\n",
       "      <td>At Booking.com, I implemented an epsilon-greed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type     Category                                           Question  \\\n",
       "0   Technical           ML  Explain the difference between L1 and L2 regul...   \n",
       "1   Technical           ML  How would you detect and handle outliers in a ...   \n",
       "2   Technical           ML  Design a simple recommendation system for an o...   \n",
       "3  Behavioral  Soft Skills  Tell me about a time when you had to learn a n...   \n",
       "4   Technical           ML  How would you design and evaluate a multi-arme...   \n",
       "\n",
       "                                              Answer  \n",
       "0  In my graduate research project at Stanford, I...  \n",
       "1  During my internship at Tesla, I worked with s...  \n",
       "2  I'd start with a collaborative filtering appro...  \n",
       "3  During my internship at Facebook, I needed to ...  \n",
       "4  At Booking.com, I implemented an epsilon-greed...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the two dataframes with scaped data\n",
    "df_combined = pd.concat([df, df1], ignore_index=True)\n",
    "df_combined.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the scraped data to the csv file\n",
    "df_combined.to_csv('interview_qa_combined.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Explain the central limit theorem and give exa...</td>\n",
       "      <td>The center limit theorem states that if any ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Briefly explain the A/B testing and its applic...</td>\n",
       "      <td>A/B testing helps us to determine whether a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Describe briefly the hypothesis testing and p-...</td>\n",
       "      <td>In Layman's terms:- Hypothesis test is where y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Given a left-skewed distribution that has a me...</td>\n",
       "      <td>Left skewed distribution means the tail of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>What is the meaning of selection bias and how ...</td>\n",
       "      <td>Sampling bias is the phenomenon that occurs wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                  Category  \\\n",
       "0  Technical  Statistics & Probability   \n",
       "1  Technical  Statistics & Probability   \n",
       "2  Technical  Statistics & Probability   \n",
       "3  Technical  Statistics & Probability   \n",
       "4  Technical  Statistics & Probability   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Explain the central limit theorem and give exa...   \n",
       "1  Briefly explain the A/B testing and its applic...   \n",
       "2  Describe briefly the hypothesis testing and p-...   \n",
       "3  Given a left-skewed distribution that has a me...   \n",
       "4  What is the meaning of selection bias and how ...   \n",
       "\n",
       "                                              Answer  \n",
       "0  The center limit theorem states that if any ra...  \n",
       "1  A/B testing helps us to determine whether a ch...  \n",
       "2  In Layman's terms:- Hypothesis test is where y...  \n",
       "3  Left skewed distribution means the tail of the...  \n",
       "4  Sampling bias is the phenomenon that occurs wh...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('interview_qa_combined.csv', encoding='ISO-8859-1') #\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Description***\n",
    "\n",
    "The data to be used for this project is a collection of QA-pairs asked in a data science interview. So we'll have the questions asked in a data science interview then how they are answered. For easy identification of the questions we then categorize every question into categories (SQL, statistics & probability, Machine Learning, Python, soft skills).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type        0\n",
       "Category    0\n",
       "Question    0\n",
       "Answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "621    False\n",
       "622    False\n",
       "623    False\n",
       "624    False\n",
       "625    False\n",
       "Length: 626, dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicates\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Explain the central limit theorem and give exa...</td>\n",
       "      <td>The center limit theorem states that if any ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Briefly explain the A/B testing and its applic...</td>\n",
       "      <td>A/B testing helps us to determine whether a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Describe briefly the hypothesis testing and p-...</td>\n",
       "      <td>In Layman's terms:- Hypothesis test is where y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>Given a left-skewed distribution that has a me...</td>\n",
       "      <td>Left skewed distribution means the tail of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technical</td>\n",
       "      <td>Statistics &amp; Probability</td>\n",
       "      <td>What is the meaning of selection bias and how ...</td>\n",
       "      <td>Sampling bias is the phenomenon that occurs wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type                  Category  \\\n",
       "0  Technical  Statistics & Probability   \n",
       "1  Technical  Statistics & Probability   \n",
       "2  Technical  Statistics & Probability   \n",
       "3  Technical  Statistics & Probability   \n",
       "4  Technical  Statistics & Probability   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Explain the central limit theorem and give exa...   \n",
       "1  Briefly explain the A/B testing and its applic...   \n",
       "2  Describe briefly the hypothesis testing and p-...   \n",
       "3  Given a left-skewed distribution that has a me...   \n",
       "4  What is the meaning of selection bias and how ...   \n",
       "\n",
       "                                              Answer  \n",
       "0  The center limit theorem states that if any ra...  \n",
       "1  A/B testing helps us to determine whether a ch...  \n",
       "2  In Layman's terms:- Hypothesis test is where y...  \n",
       "3  Left skewed distribution means the tail of the...  \n",
       "4  Sampling bias is the phenomenon that occurs wh...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing whitespaces\n",
    "data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text on the data\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by fixing encoding issues, removing unwanted characters,\n",
    "    and normalizing spaces.\n",
    "    \"\"\"\n",
    "    # Fix encoding issues\n",
    "    text = text.encode(\"utf-8\").decode(\"utf-8\", \"ignore\")  \n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "    # Remove emojis (optional, if you want no emoji left)\n",
    "    #text = re.sub(r'[^\\w\\s,]', '', text)  \n",
    "\n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply Cleaning to Question and Answer Columns\n",
    "data[\"Question\"] = data[\"Question\"].apply(clean_text)\n",
    "data[\"Answer\"] = data[\"Answer\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('interview_qa_combined.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***NLP Modelling***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e5-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "\n",
      "=== Interview Question ===\n",
      "Explain the difference between GROUP BY and HAVING clauses in SQL.\n",
      "\n",
      "Similarity Score: 0.8900\n",
      "Excellent! Your answer closely matches the expected response.\n"
     ]
    }
   ],
   "source": [
    "questions = data[\"Question\"].tolist()\n",
    "ideal_answers = data[\"Answer\"].tolist()\n",
    "\n",
    "# ----------- Load the Model -----------\n",
    "print(\"Loading model...\")\n",
    "model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "\n",
    "def preprocess(text):\n",
    "    return \"query: \" + text.strip()\n",
    "\n",
    "# ----------- Select a Random Question -----------\n",
    "random_idx = random.randint(0, len(data) - 1)\n",
    "selected_question = questions[random_idx]\n",
    "selected_ideal_answer = ideal_answers[random_idx]\n",
    "\n",
    "print(\"\\n=== Interview Question ===\")\n",
    "print(selected_question)\n",
    "\n",
    "# ----------- Get User Answer -----------\n",
    "user_input = input(\"\\nYour Answer:\\n\")\n",
    "\n",
    "# ----------- Embed Both Answers -----------\n",
    "user_embedding = model.encode(preprocess(user_input), convert_to_tensor=True)\n",
    "ideal_embedding = model.encode(preprocess(selected_ideal_answer), convert_to_tensor=True)\n",
    "\n",
    "# ----------- Compute Similarity -----------\n",
    "cos_score = util.cos_sim(user_embedding, ideal_embedding).item()\n",
    "print(f\"\\nSimilarity Score: {cos_score:.4f}\")\n",
    "\n",
    "# ----------- Provide Feedback -----------\n",
    "def get_feedback(score):\n",
    "    if score >= 0.8:\n",
    "        return \"Excellent! Your answer closely matches the expected response.\"\n",
    "    elif score >= 0.5:\n",
    "        return \"Partial match. You may need to elaborate or add more detail.\"\n",
    "    else:\n",
    "        return \"Low match. Consider revisiting the key concepts in your response.\"\n",
    "\n",
    "print(get_feedback(cos_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interview Question ===\n",
      "What is the difference betweeen K nearest neighbors and K means\n",
      "\n",
      "Similarity Score (User Answer vs Actual Answer): 0.8851\n",
      "Great! Your answer is very close to the correct answer.\n"
     ]
    }
   ],
   "source": [
    "# Load DistilBERT tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Function to get sentence embeddings from DistilBERT\n",
    "def get_distilbert_embeddings(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Forward pass through DistilBERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the embeddings (we use the last hidden state, which corresponds to [CLS] token embeddings)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling of all token embeddings\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Function to ask user a question and compare answer with actual answer\n",
    "def ask_question_and_evaluate(data):\n",
    "    # Select a random question from your dataset (or choose a specific question)\n",
    "    question = data['Question'].sample().iloc[0]\n",
    "    actual_answer = data[data['Question'] == question]['Answer'].iloc[0]\n",
    "    print(\"\\n=== Interview Question ===\")\n",
    "    print(question)\n",
    "    #print(\"Actual Answer: \", actual_answer)  # For reference in evaluation, can be removed if not needed\n",
    "\n",
    "    # Ask user for their answer\n",
    "    user_answer = input(\"\\nYour Answer:\\n\")\n",
    "\n",
    "    # Compute embeddings for the question, user answer, and actual answer\n",
    "    question_embedding = get_distilbert_embeddings(question)\n",
    "    user_answer_embedding = get_distilbert_embeddings(user_answer)\n",
    "    actual_answer_embedding = get_distilbert_embeddings(actual_answer)\n",
    "\n",
    "    # Calculate cosine similarity between user's answer and actual answer embeddings\n",
    "    similarity = cosine_similarity(user_answer_embedding, actual_answer_embedding)\n",
    "    similarity_score = similarity[0][0]\n",
    "\n",
    "    # Display similarity score\n",
    "    print(f\"\\nSimilarity Score (User Answer vs Actual Answer): {similarity_score:.4f}\")\n",
    "\n",
    "    # Provide feedback based on similarity score\n",
    "    if similarity_score > 0.8:\n",
    "        print(\"Great! Your answer is very close to the correct answer.\")\n",
    "    elif similarity_score > 0.5:\n",
    "        print(\"Your answer is somewhat relevant, but you might need to refine it further.\")\n",
    "    else:\n",
    "        print(\"Your answer seems to be off from the correct answer. Try again with more details.\")\n",
    "\n",
    "\n",
    "# Ask the user a question and evaluate their answer\n",
    "ask_question_and_evaluate(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SentenceBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interview Question ===\n",
      "What is the difference between online and batch learning?\n",
      "\n",
      "Similarity Score (User Answer vs Actual Answer): 0.0253\n",
      "Your answer seems to be off from the correct answer. Try again with more details.\n"
     ]
    }
   ],
   "source": [
    "# Load Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Function to get sentence embeddings from Sentence-BERT\n",
    "def get_sentencebert_embeddings(text):\n",
    "    return model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "# Function to ask user a question and compare answer with actual answer\n",
    "def ask_question_and_evaluate(data):\n",
    "    # Select a random question from your dataset (or choose a specific question)\n",
    "    question = data['Question'].sample().iloc[0]\n",
    "    actual_answer = data[data['Question'] == question]['Answer'].iloc[0]\n",
    "    print(\"\\n=== Interview Question ===\")\n",
    "    print(question)\n",
    "    #print(\"Actual Answer: \", actual_answer)  # For reference, can be removed in the final version\n",
    "\n",
    "    # Ask user for their answer\n",
    "    user_answer = input(\"\\nYour Answer:\\n\")\n",
    "\n",
    "    # Compute embeddings for the user answer and actual answer\n",
    "    user_answer_embedding = get_sentencebert_embeddings(user_answer)\n",
    "    actual_answer_embedding = get_sentencebert_embeddings(actual_answer)\n",
    "\n",
    "    # Calculate cosine similarity between user's answer and actual answer embeddings\n",
    "    similarity = cosine_similarity([user_answer_embedding], [actual_answer_embedding])\n",
    "    similarity_score = similarity[0][0]\n",
    "\n",
    "    # Display similarity score\n",
    "    print(f\"\\nSimilarity Score (User Answer vs Actual Answer): {similarity_score:.4f}\")\n",
    "\n",
    "    # Provide feedback based on similarity score\n",
    "    if similarity_score > 0.8:\n",
    "        print(\"Great! Your answer is very close to the correct answer.\")\n",
    "    elif similarity_score > 0.5:\n",
    "        print(\"Your answer is somewhat relevant, but you might need to refine it further.\")\n",
    "    else:\n",
    "        print(\"Your answer seems to be off from the correct answer. Try again with more details.\")\n",
    "\n",
    "# Ask the user a question and evaluate their answer\n",
    "ask_question_and_evaluate(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluate these models***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data[\"Question\"].tolist()\n",
    "answers = data[\"Answer\"].tolist()\n",
    "\n",
    "e5base_model = SentenceTransformer(\"intfloat/e5-base-v2\")\n",
    "\n",
    "# Load DistilBERT model (needs tokenizer too)\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "distilbert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "distilbert_tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Load Sentence-BERT model (SBERT)\n",
    "sbert_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilBERT embedding\n",
    "def distilbert_embedding(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# E5 embedding (SentenceTransformer-based)\n",
    "def e5_embedding(text, model):\n",
    "    return model.encode(\"query: \" + text, convert_to_tensor=True)\n",
    "\n",
    "# Evaluate similarity across 3 models\n",
    "def evaluate_similarity(user_answer, correct_answer):\n",
    "    \"\"\"Compute similarity using SBERT, E5-base, and DistilBERT.\"\"\"\n",
    "    \n",
    "    # SBERT\n",
    "    user_vector_sbert = sbert_model.encode(user_answer, convert_to_tensor=True)\n",
    "    correct_vector_sbert = sbert_model.encode(correct_answer, convert_to_tensor=True)\n",
    "\n",
    "    # E5-base\n",
    "    user_vector_e5 = e5_embedding(user_answer, e5base_model)\n",
    "    correct_vector_e5 = e5_embedding(correct_answer, e5base_model)\n",
    "\n",
    "    # DistilBERT\n",
    "    user_vector_distilbert = distilbert_embedding(user_answer, distilbert_tokenizer, distilbert_model)\n",
    "    correct_vector_distilbert = distilbert_embedding(correct_answer, distilbert_tokenizer, distilbert_model)\n",
    "\n",
    "    # Compute cosine similarities\n",
    "    similarity_sbert = util.pytorch_cos_sim(user_vector_sbert, correct_vector_sbert).item()\n",
    "    similarity_e5 = util.pytorch_cos_sim(user_vector_e5, correct_vector_e5).item()\n",
    "    similarity_distilbert = cosine_similarity([user_vector_distilbert], [correct_vector_distilbert])[0][0]\n",
    "\n",
    "    return {\n",
    "        \"sbert\": similarity_sbert,\n",
    "        \"e5-base\": similarity_e5,\n",
    "        \"distilbert\": similarity_distilbert\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interview Question ===\n",
      "Describe a situation where you had to make a difficult decision with limited data.\n",
      "\n",
      "Correct Answer: In a supply chain optimization project, we lacked detailed data for certain regions. I decided to use historical trends as a proxy and built sensitivity analyses to assess the potential risks. This allowed the team to proceed with a robust strategy while monitoring for updates. The decision minimized delays and kept the project on schedule\n",
      "🔹 SBERT Similarity Score: 0.0473\n",
      "🔹 E5-base Similarity Score: 0.6752\n",
      "🔹 DistilBERT Similarity Score: 0.5153\n",
      "Best Model for this answer: E5-base\n",
      "\n",
      "=== Interview Question ===\n",
      "How Do You Assess the Statistical Significance of an Insight?\n",
      "\n",
      "Correct Answer: You would perform hypothesis testing to determine statistical significance. First, you would state the null hypothesis and alternative hypothesis. Second, you would calculate the p-value, the probability of obtaining the observed results of a test assuming that the null hypothesis is true. Last, you would set the level of the significance (alpha), and if the p-value is less than the alpha, you would reject the null. In other words, the result is statistically significant.\n",
      "🔹 SBERT Similarity Score: -0.0375\n",
      "🔹 E5-base Similarity Score: 0.6852\n",
      "🔹 DistilBERT Similarity Score: 0.5777\n",
      "Best Model for this answer: E5-base\n",
      "\n",
      "=== Interview Question ===\n",
      "Mention three ways to make your model robust to outliers.\n",
      "\n",
      "Correct Answer: Investigating the outliers is always the first step in understanding how to treat them. After you understand the nature of why the outliers occurred you can apply one of the several methods mentioned [here](https://365datascience.com/career-advice/job-interview-tips/machine-learning-interview-questions-and-answers/#11:~:text=for%20large%20datasets.-,Bonus%20Question%3A%20Discuss%20how%20to%20make%20your%20model%20robust%20to%20outliers.,-There%20are%20several).\n",
      "🔹 SBERT Similarity Score: 0.2745\n",
      "🔹 E5-base Similarity Score: 0.7792\n",
      "🔹 DistilBERT Similarity Score: 0.7105\n",
      "Best Model for this answer: E5-base\n",
      "Exiting the interview. Good luck with your preparation!\n"
     ]
    }
   ],
   "source": [
    "def ask_question():\n",
    "    \"\"\"Ask a question, get user input, and compare similarity across SBERT, E5-base, and DistilBERT.\"\"\"\n",
    "    question_index = random.randint(0, len(questions) - 1)\n",
    "    question = questions[question_index]\n",
    "    correct_answer = answers[question_index]\n",
    "\n",
    "    print(f\"\\n=== Interview Question ===\")\n",
    "    print(question)\n",
    "    user_response = input(\"\\nYour Answer:\\n\")\n",
    "\n",
    "    # Get similarity scores\n",
    "    scores = evaluate_similarity(user_response, correct_answer)\n",
    "    sim_sbert = scores[\"sbert\"]\n",
    "    sim_e5 = scores[\"e5-base\"]\n",
    "    sim_distilbert = scores[\"distilbert\"]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nCorrect Answer: {correct_answer}\")\n",
    "    print(f\"🔹 SBERT Similarity Score: {sim_sbert:.4f}\")\n",
    "    print(f\"🔹 E5-base Similarity Score: {sim_e5:.4f}\")\n",
    "    print(f\"🔹 DistilBERT Similarity Score: {sim_distilbert:.4f}\")\n",
    "\n",
    "    # Determine the best model\n",
    "    best_score = max(sim_sbert, sim_e5, sim_distilbert)\n",
    "    if best_score == sim_sbert:\n",
    "        best_model = \"SBERT\"\n",
    "    elif best_score == sim_e5:\n",
    "        best_model = \"E5-base\"\n",
    "    else:\n",
    "        best_model = \"DistilBERT\"\n",
    "\n",
    "    print(f\"Best Model for this answer: {best_model}\")\n",
    "\n",
    "# Run the interview system\n",
    "while True:\n",
    "    ask_question()\n",
    "    continue_response = input(\"\\nDo you want another question? (yes/no): \").strip().lower()\n",
    "    if continue_response != \"yes\":\n",
    "        print(\"Exiting the interview. Good luck with your preparation!\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updated model names\n",
    "models = [\"SBERT\", \"E5-base\", \"DistilBERT\"]\n",
    "\n",
    "# Updated similarity scores for multiple questions\n",
    "scores = [\n",
    "   [-0.0375, 0.6852, 0.5777], \n",
    "    [0.0473, 0.6752, 0.5153],\n",
    "    [0.2745, 0.7792, 0.7105]   \n",
    "]\n",
    "\n",
    "# Convert scores into a NumPy array\n",
    "scores = np.array(scores)\n",
    "\n",
    "# Set up x-axis labels (Q1, Q2, Q3, ...)\n",
    "x_labels = [f\"Q{i+1}\" for i in range(scores.shape[0])]\n",
    "\n",
    "# Set up figure and axis\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plot each model's scores\n",
    "for i, model in enumerate(models):\n",
    "    plt.plot(x_labels, scores[:, i], marker='o', linestyle='-', label=model)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Questions\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.ylim(0, 1)  # Similarity scores range from 0 to 1\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT Average Similarity Score: 0.0948\n",
      "E5-base Average Similarity Score: 0.7132\n",
      "DistilBERT Average Similarity Score: 0.6012\n"
     ]
    }
   ],
   "source": [
    "# Calculate average similarity for each model\n",
    "average_scores = scores.mean(axis=0)\n",
    "\n",
    "# Display average similarity per model\n",
    "for model, avg_score in zip(models, average_scores):\n",
    "    print(f\"{model} Average Similarity Score: {avg_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model evaluation comparison (Pearson correlation with ground truth scores):\n",
      "E5-base: 1.000\n",
      "SBERT: 1.000\n",
      "DistilBERT: -0.302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load models once\n",
    "e5_model = SentenceTransformer(\"intfloat/e5-base\")\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "distilbert_model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")\n",
    "\n",
    "# Sample data: list of dicts with question, user_answer, ideal_answer, ground truth score (0-10)\n",
    "sample_data = sample_data = [\n",
    "    {\n",
    "        \"question\": \"Why is mean square error a bad measure of model performance? What would you suggest instead?\",\n",
    "        \"ideal_answer\": \"Mean Squared Error (MSE) gives a relatively high weight to large errors therefore, MSE tends to put too much emphasis on large deviations. A more robust alternative is MAE (mean absolute deviation).\",\n",
    "        \"user_answer\": \"MSE squares errors and that might be bad if there are big errors. MAE could be better.\",\n",
    "        \"score\": 6  # partial answer, roughly 0.6 * 10\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is mean square error a bad measure of model performance? What would you suggest instead?\",\n",
    "        \"ideal_answer\": \"Mean Squared Error (MSE) gives a relatively high weight to large errors therefore, MSE tends to put too much emphasis on large deviations. A more robust alternative is MAE (mean absolute deviation).\",\n",
    "        \"user_answer\": \"MSE is used for errors. I think accuracy is better.\",\n",
    "        \"score\": 2  # poor answer, roughly 0.2 * 10\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain what a false positive and a false negative are. Why is it important to distinguish these from each other?\",\n",
    "        \"ideal_answer\": \"A false positive is an incorrect identification of the presence of a condition when its absent.A false negative is an incorrect identification of the absence of a condition when its actually present.An example of when false negatives are more important than false positives is when screening for cancer. Its much worse to say that someone doesnt have cancer when they do, instead of saying that someone does and later realizing that they dont.This is a subjective argument, but false positives can be worse than false negatives from a psychological point of view. For example, a false positive for winning the lottery could be a worse outcome than a false negative because people normally dont expect to win the lottery anyway.\",\n",
    "        \"user_answer\": \"False positive means detecting something that isn’t there, false negative means missing something that is there. Both are important for accuracy.\",\n",
    "        \"score\": 6  # partial answer\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain what a false positive and a false negative are. Why is it important to distinguish these from each other?\",\n",
    "        \"ideal_answer\": \"A false positive is an incorrect identification of the presence of a condition when its absent.A false negative is an incorrect identification of the absence of a condition when its actually present.An example of when false negatives are more important than false positives is when screening for cancer. Its much worse to say that someone doesnt have cancer when they do, instead of saying that someone does and later realizing that they dont.This is a subjective argument, but false positives can be worse than false negatives from a psychological point of view. For example, a false positive for winning the lottery could be a worse outcome than a false negative because people normally dont expect to win the lottery anyway.\",\n",
    "\n",
    "        \"user_answer\": \"False positive and false negative are just mistakes in predictions.\",\n",
    "        \"score\": 2  # poor answer\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def evaluate_with_e5(question, user_answer, ideal_answer):\n",
    "    emb_user = e5_model.encode(f\"query: {user_answer}\", convert_to_tensor=True)\n",
    "    emb_ideal = e5_model.encode(f\"passage: {ideal_answer}\", convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(emb_user, emb_ideal).item()\n",
    "    score = int(round(similarity * 10))\n",
    "    return score\n",
    "\n",
    "def evaluate_with_sbert(question, user_answer, ideal_answer):\n",
    "    emb_user = sbert_model.encode(user_answer, convert_to_tensor=True)\n",
    "    emb_ideal = sbert_model.encode(ideal_answer, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(emb_user, emb_ideal).item()\n",
    "    score = int(round(similarity * 10))\n",
    "    return score\n",
    "\n",
    "def evaluate_with_distilbert(question, user_answer, ideal_answer):\n",
    "    emb_user = distilbert_model.encode(user_answer, convert_to_tensor=True)\n",
    "    emb_ideal = distilbert_model.encode(ideal_answer, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(emb_user, emb_ideal).item()\n",
    "    score = int(round(similarity * 10))\n",
    "    return score\n",
    "\n",
    "def compare_models(sample_data):\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    models = {\n",
    "        \"E5-base\": evaluate_with_e5,\n",
    "        \"SBERT\": evaluate_with_sbert,\n",
    "        \"DistilBERT\": evaluate_with_distilbert\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, eval_fn in models.items():\n",
    "        predicted_scores = []\n",
    "        ground_truth_scores = []\n",
    "        for sample in sample_data:\n",
    "            predicted_score = eval_fn(sample['question'], sample['user_answer'], sample['ideal_answer'])\n",
    "            predicted_scores.append(predicted_score)\n",
    "            ground_truth_scores.append(sample['score'])\n",
    "\n",
    "        corr, _ = pearsonr(predicted_scores, ground_truth_scores)\n",
    "        results[model_name] = corr\n",
    "\n",
    "    print(\"Model evaluation comparison (Pearson correlation with ground truth scores):\")\n",
    "    for model_name, corr in results.items():\n",
    "        print(f\"{model_name}: {corr:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    compare_models(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E5-base RMSE: 0.855\n",
      "SBERT RMSE: 5.717\n",
      "DistilBERT RMSE: 3.981\n"
     ]
    }
   ],
   "source": [
    "# Load models once\n",
    "e5_model = SentenceTransformer(\"intfloat/e5-base\")\n",
    "sbert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "distilbert_model = SentenceTransformer(\"distilbert-base-nli-stsb-mean-tokens\")  # or another suitable DistilBERT model\n",
    "\n",
    "# Example dataset: list of (question, ideal_answer, user_answer)\n",
    "data = sample_data = [\n",
    "    {\n",
    "        \"question\": \"Why is mean square error a bad measure of model performance? What would you suggest instead?\",\n",
    "        \"ideal_answer\": \"Mean Squared Error (MSE) gives a relatively high weight to large errors therefore, MSE tends to put too much emphasis on large deviations. A more robust alternative is MAE (mean absolute deviation).\",\n",
    "        \"user_answer\": \"MSE squares errors and that might be bad if there are big errors. MAE could be better.\",\n",
    "        #\"score\": 6  # partial answer, roughly 0.6 * 10\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Why is mean square error a bad measure of model performance? What would you suggest instead?\",\n",
    "        \"ideal_answer\": \"Mean Squared Error (MSE) gives a relatively high weight to large errors therefore, MSE tends to put too much emphasis on large deviations. A more robust alternative is MAE (mean absolute deviation).\",\n",
    "        \"user_answer\": \"MSE is used for errors. I think accuracy is better.\",\n",
    "        #\"score\": 2  # poor answer, roughly 0.2 * 10\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain what a false positive and a false negative are. Why is it important to distinguish these from each other?\",\n",
    "        \"ideal_answer\": \"A false positive is an incorrect identification of the presence of a condition when its absent.A false negative is an incorrect identification of the absence of a condition when its actually present.An example of when false negatives are more important than false positives is when screening for cancer. Its much worse to say that someone doesnt have cancer when they do, instead of saying that someone does and later realizing that they dont.This is a subjective argument, but false positives can be worse than false negatives from a psychological point of view. For example, a false positive for winning the lottery could be a worse outcome than a false negative because people normally dont expect to win the lottery anyway.\",\n",
    "        \"user_answer\": \"False positive means detecting something that isn’t there, false negative means missing something that is there. Both are important for accuracy.\",\n",
    "        #\"score\": 6  # partial answer\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Explain what a false positive and a false negative are. Why is it important to distinguish these from each other?\",\n",
    "        \"ideal_answer\": \"A false positive is an incorrect identification of the presence of a condition when its absent.A false negative is an incorrect identification of the absence of a condition when its actually present.An example of when false negatives are more important than false positives is when screening for cancer. Its much worse to say that someone doesnt have cancer when they do, instead of saying that someone does and later realizing that they dont.This is a subjective argument, but false positives can be worse than false negatives from a psychological point of view. For example, a false positive for winning the lottery could be a worse outcome than a false negative because people normally dont expect to win the lottery anyway.\",\n",
    "\n",
    "        \"user_answer\": \"False positive and false negative are just mistakes in predictions.\",\n",
    "        #\"score\": 2  # poor answer\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "ground_truth_scores = [10] * len(data)  # Perfect scores for ideal answers\n",
    "\n",
    "e5_scores = []\n",
    "sbert_scores = []\n",
    "distilbert_scores = []\n",
    "\n",
    "for question, ideal_answer, user_answer in data:\n",
    "    # Encode answers and compute cosine similarity for E5\n",
    "    emb_user_e5 = e5_model.encode(user_answer, convert_to_tensor=True)\n",
    "    emb_ideal_e5 = e5_model.encode(ideal_answer, convert_to_tensor=True)\n",
    "    sim_e5 = util.cos_sim(emb_user_e5, emb_ideal_e5).item()\n",
    "    score_e5 = sim_e5 * 10\n",
    "    e5_scores.append(score_e5)\n",
    "\n",
    "    # SBERT similarity\n",
    "    emb_user_sbert = sbert_model.encode(user_answer, convert_to_tensor=True)\n",
    "    emb_ideal_sbert = sbert_model.encode(ideal_answer, convert_to_tensor=True)\n",
    "    sim_sbert = util.cos_sim(emb_user_sbert, emb_ideal_sbert).item()\n",
    "    score_sbert = sim_sbert * 10\n",
    "    sbert_scores.append(score_sbert)\n",
    "\n",
    "    # DistilBERT similarity\n",
    "    emb_user_distil = distilbert_model.encode(user_answer, convert_to_tensor=True)\n",
    "    emb_ideal_distil = distilbert_model.encode(ideal_answer, convert_to_tensor=True)\n",
    "    sim_distil = util.cos_sim(emb_user_distil, emb_ideal_distil).item()\n",
    "    score_distil = sim_distil * 10\n",
    "    distilbert_scores.append(score_distil)\n",
    "\n",
    "# Calculate RMSE (manual sqrt for compatibility)\n",
    "rmse_e5 = np.sqrt(mean_squared_error(ground_truth_scores, e5_scores))\n",
    "rmse_sbert = np.sqrt(mean_squared_error(ground_truth_scores, sbert_scores))\n",
    "rmse_distil = np.sqrt(mean_squared_error(ground_truth_scores, distilbert_scores))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"E5-base RMSE: {rmse_e5:.3f}\")\n",
    "print(f\"SBERT RMSE: {rmse_sbert:.3f}\")\n",
    "print(f\"DistilBERT RMSE: {rmse_distil:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
